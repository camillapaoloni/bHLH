{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100656fd",
   "metadata": {},
   "source": [
    "# Ortholog Retrieval and InterProScan Integration\n",
    "\n",
    "This notebook retrieves orthologs via Ensembl REST, prepares the FASTA for InterProScan, parses InterProScan output, and merges ortholog metadata with bHLH domain coordinates.\n",
    "\n",
    "**Inputs**\n",
    "- `data/intermediate/table_input.csv`\n",
    "- `data/intermediate/Metadata_CSVs/InterPro_Domains_cleaned.csv`\n",
    "- `data/intermediate/Metadata_CSVs/Transcript_Attributes_cleaned.csv`\n",
    "- `data/intermediate/interpro/interpro_output.tsv` (from InterProScan)\n",
    "\n",
    "**Outputs**\n",
    "- `data/intermediate/orthologs/homology_results.csv`\n",
    "- `data/intermediate/interpro/interpro_input.fasta`\n",
    "- `data/intermediate/interpro/OutputInterProScan.tsv`\n",
    "- `data/intermediate/interpro/IPR011598_IPRScan_final.tsv`\n",
    "- `data/intermediate/orthologs/in&out_bHLH_data.csv`\n",
    "- `data/intermediate/orthologs/annotated_bHLH_merged_data.csv`\n",
    "\n",
    "**Note**: Set `BHLH_PROJECT_ROOT` if running from a different working directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path(__import__(\"os\").getenv(\"BHLH_PROJECT_ROOT\", \".\")).resolve()\n",
    "\n",
    "def p(*parts):\n",
    "    return str(project_root.joinpath(*parts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5bdca",
   "metadata": {},
   "source": [
    "## 1) Load inputs and get ENSG list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3451e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = pd.read_csv(p(\"data\", \"intermediate\", \"Metadata_CSVs\", \"Transcript_Attributes_cleaned.csv\"))\n",
    "interpro = pd.read_csv(p(\"data\", \"intermediate\", \"Metadata_CSVs\", \"InterPro_Domains_cleaned.csv\"))\n",
    "\n",
    "table_input = pd.read_csv(p(\"data\", \"intermediate\", \"table_input.csv\"))\n",
    "ENSG_IDs = table_input[\"ensembl_gene_id\"].dropna().unique().tolist()\n",
    "print(\"ENSG IDs:\", len(ENSG_IDs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba5c858",
   "metadata": {},
   "source": [
    "## 2) Define target species and compara group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_species = [\n",
    "    \"drosophila_melanogaster\", \"nematostella_vectensis\", \"helobdella_robusta\",\n",
    "    \"daphnia_magna\", \"tribolium_castaneum\", \"branchiostoma_floridae\", \"bos_taurus\",\n",
    "    \"canis_lupus_familiaris\", \"danio_rerio\", \"gallus_gallus\", \"gorilla_gorilla\",\n",
    "    \"lepisosteus_oculatus\", \"macaca_mulatta\", \"monodelphis_domestica\", \"mus_musculus\",\n",
    "    \"oryzias_latipes\", \"pan_troglodytes\", \"rattus_norvegicus\", \"xenopus_tropicalis\",\n",
    "    \"anolis_carolinensis\", \"anopheles_gambiae\", \"caenorhabditis_elegans\",\n",
    "    \"ciona_intestinalis\", \"ixodes_scapularis\", \"monosiga_brevicollis\",\n",
    "    \"saccharomyces_cerevisiae\", \"schizosaccharomyces_pombe\", \"neurospora_crassa\",\n",
    "    \"candida_albicans\"\n",
    "]\n",
    "\n",
    "vertebrate_species = {\n",
    "    \"bos_taurus\", \"canis_lupus_familiaris\", \"danio_rerio\", \"gallus_gallus\",\n",
    "    \"gorilla_gorilla\", \"lepisosteus_oculatus\", \"macaca_mulatta\", \"monodelphis_domestica\",\n",
    "    \"mus_musculus\", \"oryzias_latipes\", \"pan_troglodytes\", \"rattus_norvegicus\",\n",
    "    \"xenopus_tropicalis\", \"anolis_carolinensis\", \"homo_sapiens\"\n",
    "}\n",
    "\n",
    "def get_compara_group(species: str) -> str:\n",
    "    return \"vertebrates\" if species in vertebrate_species else \"pan_homology\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba8788c",
   "metadata": {},
   "source": [
    "## 3) Fetch orthologs via Ensembl REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://rest.ensembl.org/homology/id\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "results = []\n",
    "\n",
    "for gene_id in ENSG_IDs:\n",
    "    for species in target_species:\n",
    "        compara = get_compara_group(species)\n",
    "        url = f\"{base_url}/homo_sapiens/{gene_id}\"\n",
    "        params = {\n",
    "            \"target_species\": species,\n",
    "            \"compara\": compara,\n",
    "            \"type\": \"all\",\n",
    "            \"sequence\": \"protein\",\n",
    "            \"aligned\": 0,\n",
    "            \"cigar_line\": 1,\n",
    "            \"format\": \"full\",\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "        if response.ok:\n",
    "            data = response.json()\n",
    "            for homology in data.get(\"data\", [])[0].get(\"homologies\", []):\n",
    "                row = {\n",
    "                    \"query_gene\": gene_id,\n",
    "                    \"target_species\": species,\n",
    "                    \"compara\": compara,\n",
    "                    \"homology_type\": homology.get(\"type\"),\n",
    "                    \"taxonomy_level\": homology.get(\"taxonomy_level\"),\n",
    "                    \"dn_ds\": homology.get(\"dn_ds\"),\n",
    "                    \"source_id\": homology[\"source\"].get(\"id\"),\n",
    "                    \"source_protein\": homology[\"source\"].get(\"protein_id\"),\n",
    "                    \"source_seq\": homology[\"source\"].get(\"seq\"),\n",
    "                    \"source_species\": homology[\"source\"].get(\"species\"),\n",
    "                    \"source_perc_id\": homology[\"source\"].get(\"perc_id\"),\n",
    "                    \"source_perc_pos\": homology[\"source\"].get(\"perc_pos\"),\n",
    "                    \"target_id\": homology[\"target\"].get(\"id\"),\n",
    "                    \"target_protein\": homology[\"target\"].get(\"protein_id\"),\n",
    "                    \"target_seq\": homology[\"target\"].get(\"seq\"),\n",
    "                    \"target_species_name\": homology[\"target\"].get(\"species\"),\n",
    "                    \"target_perc_id\": homology[\"target\"].get(\"perc_id\"),\n",
    "                    \"target_perc_pos\": homology[\"target\"].get(\"perc_pos\"),\n",
    "                    \"cigar_line\": homology[\"target\"].get(\"cigar_line\"),\n",
    "                }\n",
    "                results.append(row)\n",
    "        else:\n",
    "            print(f\"Error for {gene_id} -> {species} ({compara}): {response.status_code}\")\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Move sequences to the end for readability\n",
    "cols = list(results_df.columns)\n",
    "for col in [\"source_seq\", \"target_seq\"]:\n",
    "    if col in cols:\n",
    "        cols.remove(col)\n",
    "        cols.append(col)\n",
    "results_df = results_df[cols]\n",
    "\n",
    "out_csv = p(\"data\", \"intermediate\", \"orthologs\", \"homology_results.csv\")\n",
    "Path(out_csv).parent.mkdir(parents=True, exist_ok=True)\n",
    "results_df.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c17e78",
   "metadata": {},
   "source": [
    "## 4) Build InterProScan input FASTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "written_queries = set()\n",
    "\n",
    "out_fasta = p(\"data\", \"intermediate\", \"interpro\", \"interpro_input.fasta\")\n",
    "Path(out_fasta).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(out_fasta, \"w\") as f:\n",
    "    for _, row in results_df.iterrows():\n",
    "        query_key = f\"{row['query_gene']}_{row['source_id']}\"\n",
    "        target_key = f\"{row['query_gene']}_{row['target_id']}\"\n",
    "\n",
    "        if query_key not in written_queries:\n",
    "            f.write(f\">{query_key}\n",
    "{row['source_seq']}\n",
    "\")\n",
    "            written_queries.add(query_key)\n",
    "\n",
    "        f.write(f\">{target_key}\n",
    "{row['target_seq']}\n",
    "\")\n",
    "\n",
    "print(\"Saved:\", out_fasta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fab9a0",
   "metadata": {},
   "source": [
    "## 5) Parse InterProScan output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1858373",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpro_out = pd.read_csv(p(\"data\", \"intermediate\", \"interpro\", \"interpro_output.tsv\"), sep=\"\t\", header=None)\n",
    "interpro_out.columns = [\n",
    "    \"FASTA Header\", \"MD5 Code\", \"Length_target\", \"Analysis\", \"Signature Accession\",\n",
    "    \"Signature Description\", \"Start_T\", \"Stop_T\", \"Score\", \"Status\", \"Date\",\n",
    "    \"InterPro ID\", \"InterPro Description\"\n",
    "]\n",
    "\n",
    "out_tsv = p(\"data\", \"intermediate\", \"interpro\", \"OutputInterProScan.tsv\")\n",
    "interpro_out.to_csv(out_tsv, sep=\"\t\", index=False)\n",
    "print(\"Saved:\", out_tsv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc0b01e",
   "metadata": {},
   "source": [
    "## 6) Filter bHLH domains (IPR011598) and recover PF00010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63326006",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipr_df = interpro_out[interpro_out[\"InterPro ID\"] == \"IPR011598\"].copy()\n",
    "pf00010_df = ipr_df[ipr_df[\"Signature Accession\"] == \"PF00010\"].copy()\n",
    "\n",
    "pf00010_df[\"domain_length\"] = pf00010_df[\"Stop_T\"] - pf00010_df[\"Start_T\"]\n",
    "\n",
    "pf00010_headers = set(pf00010_df[\"FASTA Header\"])\n",
    "all_headers = set(ipr_df[\"FASTA Header\"])\n",
    "\n",
    "missing_pf00010_headers = all_headers - pf00010_headers\n",
    "recovery_rows = ipr_df[\n",
    "    ipr_df[\"FASTA Header\"].isin(missing_pf00010_headers) &\n",
    "    ipr_df[\"Start_T\"].notnull() &\n",
    "    ipr_df[\"Stop_T\"].notnull()\n",
    "].copy()\n",
    "\n",
    "recovery_rows[\"domain_length\"] = recovery_rows[\"Stop_T\"] - recovery_rows[\"Start_T\"]\n",
    "\n",
    "best_recovery = (\n",
    "    recovery_rows\n",
    "    .sort_values(\"domain_length\", ascending=False)\n",
    "    .drop_duplicates(\"FASTA Header\")\n",
    ")\n",
    "\n",
    "final_df = pd.concat([pf00010_df, best_recovery])\n",
    "\n",
    "out_final = p(\"data\", \"intermediate\", \"interpro\", \"IPR011598_IPRScan_final.tsv\")\n",
    "final_df.to_csv(out_final, sep=\"\t\", index=False)\n",
    "print(\"Saved:\", out_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468cdeec",
   "metadata": {},
   "source": [
    "## 7) Merge InterProScan with orthologs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpro_file_path = p(\"data\", \"intermediate\", \"interpro\", \"IPR011598_IPRScan_final.tsv\")\n",
    "ortholog_file_path = p(\"data\", \"intermediate\", \"orthologs\", \"homology_results.csv\")\n",
    "output_file_path = p(\"data\", \"intermediate\", \"orthologs\", \"in&out_bHLH_data.csv\")\n",
    "\n",
    "df_interpro = pd.read_csv(interpro_file_path, sep=\"\t\")\n",
    "df_ortholog = pd.read_csv(ortholog_file_path)\n",
    "\n",
    "if df_ortholog.columns[0].strip() == \"\" or \"Unnamed\" in df_ortholog.columns[0]:\n",
    "    df_ortholog = df_ortholog.iloc[:, 1:]\n",
    "\n",
    "split_header = df_interpro[\"FASTA Header\"].str.split(\"_\", n=1, expand=True)\n",
    "df_interpro[\"InterPro_QueryGene\"] = split_header[0]\n",
    "df_interpro[\"InterPro_ScannedProteinID\"] = split_header[1]\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    df_ortholog,\n",
    "    df_interpro,\n",
    "    left_on=[\"query_gene\", \"target_id\"],\n",
    "    right_on=[\"InterPro_QueryGene\", \"InterPro_ScannedProteinID\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "for col in [\"InterPro_QueryGene\", \"InterPro_ScannedProteinID\"]:\n",
    "    if col in merged_df.columns:\n",
    "        merged_df = merged_df.drop(columns=[col])\n",
    "\n",
    "# Move sequences to the end\n",
    "cols = list(merged_df.columns)\n",
    "for col in [\"source_seq\", \"target_seq\"]:\n",
    "    if col in cols:\n",
    "        cols.remove(col)\n",
    "        cols.append(col)\n",
    "merged_df = merged_df[cols]\n",
    "\n",
    "merged_df.to_csv(output_file_path, index=False)\n",
    "print(\"Saved:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370ba18",
   "metadata": {},
   "source": [
    "## 8) Enrich with human bHLH coordinates and export final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d7d4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df = pd.read_csv(p(\"data\", \"intermediate\", \"orthologs\", \"in&out_bHLH_data.csv\"))\n",
    "info_df = pd.read_csv(p(\"data\", \"intermediate\", \"table_input.csv\"))\n",
    "\n",
    "columns_to_add = [\"ensembl_gene_id\", \"HGNC symbol\", \"interpro_start\", \"interpro_end\", \"length\"]\n",
    "info_subset = info_df[columns_to_add].copy()\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    all_data_df,\n",
    "    info_subset,\n",
    "    left_on=\"query_gene\",\n",
    "    right_on=\"ensembl_gene_id\",\n",
    "    how=\"left\",\n",
    ").drop(columns=[\"ensembl_gene_id\"])\n",
    "\n",
    "# Rename and compute relative positions\n",
    "\n",
    "df_merged = df_merged.rename(columns={\n",
    "    \"interpro_start\": \"Start_Q\",\n",
    "    \"interpro_end\": \"Stop_Q\",\n",
    "    \"length\": \"Length_query\",\n",
    "})\n",
    "\n",
    "# Relative positions\n",
    "\n",
    "df_merged[\"Rel_start_Q\"] = df_merged[\"Start_Q\"] / df_merged[\"Length_query\"]\n",
    "df_merged[\"Rel_end_Q\"] = df_merged[\"Stop_Q\"] / df_merged[\"Length_query\"]\n",
    "df_merged[\"Rel_start_T\"] = df_merged[\"Start_T\"] / df_merged[\"Length_target\"]\n",
    "df_merged[\"Rel_end_T\"] = df_merged[\"Stop_T\"] / df_merged[\"Length_target\"]\n",
    "\n",
    "# Domain lengths\n",
    "\n",
    "df_merged[\"bHLH_length_Q\"] = df_merged[\"Stop_Q\"] - df_merged[\"Start_Q\"]\n",
    "df_merged[\"bHLH_length_T\"] = df_merged[\"Stop_T\"] - df_merged[\"Start_T\"]\n",
    "df_merged[\"bHLH_rel_length_Q\"] = df_merged[\"bHLH_length_Q\"] / df_merged[\"Length_query\"]\n",
    "df_merged[\"bHLH_rel_length_T\"] = df_merged[\"bHLH_length_T\"] / df_merged[\"Length_target\"]\n",
    "\n",
    "col_order = [\n",
    "    \"HGNC symbol\", \"query_gene\", \"target_id\",\n",
    "    \"Start_Q\", \"Stop_Q\", \"Rel_start_Q\", \"Rel_end_Q\",\n",
    "    \"Start_T\", \"Stop_T\", \"Rel_start_T\", \"Rel_end_T\",\n",
    "    \"bHLH_length_Q\", \"bHLH_rel_length_Q\",\n",
    "    \"bHLH_length_T\", \"bHLH_rel_length_T\",\n",
    "    \"Length_query\", \"Length_target\", \"target_perc_id\", \"target_perc_pos\", \"domain_length\",\n",
    "    \"homology_type\", \"taxonomy_level\", \"compara\",\n",
    "    \"source_id\", \"source_protein\", \"source_perc_id\", \"source_perc_pos\",\n",
    "    \"target_protein\", \"target_species\", \"target_species_name\", \"Analysis\", \"Signature Accession\",\n",
    "    \"Signature Description\", \"Score\", \"cigar_line\", \"FASTA Header\", \"MD5 Code\",\n",
    "    \"source_seq\", \"target_seq\",\n",
    "]\n",
    "\n",
    "remaining_cols = [c for c in df_merged.columns if c not in col_order]\n",
    "final_cols = col_order + remaining_cols\n",
    "\n",
    "output_path = p(\"data\", \"intermediate\", \"orthologs\", \"annotated_bHLH_merged_data.csv\")\n",
    "df_merged[final_cols].to_csv(output_path, index=False)\n",
    "print(\"Saved:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e860e6e",
   "metadata": {},
   "source": [
    "## Exploratory notes (optional)\n",
    "\n",
    "- A missing gene was temporarily added (`ENSG00000120669`) to fix a discrepancy, but later inspection suggested a duplicated SOHLH entry was the real reason for the mismatch.\n",
    "- The set of target species listed above represents the current analysis scope.\n",
    "- Use `print(results_df[\"target_species_name\"].unique())` to verify the final species included.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
