{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0ef3b7",
   "metadata": {},
   "source": [
    "# Zoonomia bHLH Mapping\n",
    "\n",
    "This notebook filters Zoonomia alignments for bHLH genes, maps human bHLH domain coordinates to orthologous sequences, and compares with Ensembl/TOGA annotations.\n",
    "\n",
    "**Inputs**\n",
    "- `data/raw/Zoonomia_protaln/*.fa`\n",
    "- `data/intermediate/bHLH_StartEnd_withISO.csv`\n",
    "- `data/intermediate/orthologs/TOGA_orthologs_allSpecies.csv`\n",
    "- `data/intermediate/orthologs/annotated_bHLH_merged_data_with_gene_names.csv`\n",
    "\n",
    "**Outputs**\n",
    "- `data/intermediate/zoonomia/Zoonomia_Start_End_final.csv`\n",
    "- `outputs/reports/report_comparison.csv`\n",
    "\n",
    "**Note**: Set `BHLH_PROJECT_ROOT` if running from a different working directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c37f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "import csv\n",
    "\n",
    "project_root = Path(__import__(\"os\").getenv(\"BHLH_PROJECT_ROOT\", \".\")).resolve()\n",
    "\n",
    "def p(*parts):\n",
    "    return str(project_root.joinpath(*parts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229aa76b",
   "metadata": {},
   "source": [
    "## 1) Filter Zoonomia alignments for bHLH genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b809b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path(p(\"data\", \"raw\", \"Zoonomia_protaln\"))\n",
    "filtered_dir = input_dir / \"filtered_alignments\"\n",
    "filtered_dir.mkdir(exist_ok=True)\n",
    "\n",
    "domain_csv = Path(p(\"data\", \"intermediate\", \"bHLH_StartEnd_withISO.csv\"))\n",
    "toga_file = Path(p(\"data\", \"intermediate\", \"orthologs\", \"TOGA_orthologs_allSpecies.csv\"))\n",
    "output_file = Path(p(\"data\", \"intermediate\", \"zoonomia\", \"Zoonomia_Start_End_final.csv\"))\n",
    "output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gene_symbols = [\n",
    "    \"TFAP4\", \"MLX\", \"MLXIPL\", \"MLXIP\", \"TCFL5\", \"SOHLH1\", \"SOHLH2\", \"MYC\", \"MYCN\", \"MYCL\", \"MAX\", \"MNT\",\n",
    "    \"MXD3\", \"MXD4\", \"MXI1\", \"MXD1\", \"SREBF2\", \"SREBF1\", \"MITF\", \"TFE3\", \"TFEC\", \"TFEB\", \"USF3\", \"USF2\", \"USF1\",\n",
    "    \"NCOA1\", \"NCOA2\", \"NCOA3\", \"NPAS2\", \"CLOCK\", \"ARNTL2\", \"ARNTL\", \"ARNT2\", \"ARNT\", \"NPAS4\", \"AHRR\", \"AHR\",\n",
    "    \"SIM2\", \"SIM1\", \"NPAS3\", \"NPAS1\", \"HIF1A\", \"HIF3A\", \"EPAS1\", \"HELT\", \"BHLHE41\", \"BHLHE40\", \"HEYL\", \"HEY2\",\n",
    "    \"HEY1\", \"HES7\", \"HES6\", \"HES5\", \"HES3\", \"HES2\", \"HES4\", \"HES1\", \"ATOH8\", \"TCF4\", \"TCF3\", \"TCF12\", \"MYOG\",\n",
    "    \"MYF6\", \"MYOD1\", \"MYF5\", \"FIGLA\", \"ID1\", \"ID4\", \"ID3\", \"ID2\", \"ASCL2\", \"ASCL1\", \"ASCL4\", \"ASCL5\", \"ASCL3\",\n",
    "    \"TAL1\", \"LYL1\", \"TAL2\", \"NHLH2\", \"NHLH1\", \"MESP2\", \"MSGN1\", \"MESP1\", \"PTF1A\", \"FERD3L\", \"ATOH7\", \"ATOH1\",\n",
    "    \"BHLHA9\", \"BHLHA15\", \"BHLHE23\", \"BHLHE22\", \"OLIG1\", \"OLIG3\", \"OLIG2\", \"NEUROG2\", \"NEUROG3\", \"NEUROG1\",\n",
    "    \"NEUROD2\", \"NEUROD6\", \"NEUROD4\", \"NEUROD1\", \"TCF21\", \"MSC\", \"TCF24\", \"TCF23\", \"TWIST2\", \"TWIST1\", \"HAND2\",\n",
    "    \"HAND1\", \"TCF15\", \"SCX\"\n",
    "]\n",
    "\n",
    "species_map = {\n",
    "    \"Mus_protaln\": \"mus_musculus\",\n",
    "    \"Opossum_protaln\": \"monodelphis_domestica\",\n",
    "    \"Macaca_protaln\": \"macaca_mulatta\",\n",
    "    \"Bos_protaln\": \"bos_taurus\",\n",
    "    \"Rat_protaln\": \"rattus_norvegicus\",\n",
    "    \"Canis_protaln\": \"canis_lupus_familiaris\",\n",
    "    \"Chimp_protaln\": \"pan_troglodytes\",\n",
    "    \"Gorilla_protaln\": \"gorilla_gorilla\",\n",
    "}\n",
    "\n",
    "# Load TOGA transcripts\n",
    "\n",
    "df_toga = pd.read_csv(toga_file)\n",
    "df_toga[\"t_transcript_clean\"] = df_toga[\"t_transcript\"].str.split(\".\").str[0]\n",
    "toga_transcripts = set(df_toga[\"t_transcript_clean\"])\n",
    "\n",
    "# Filter fasta files\n",
    "\n",
    "def extract_gene(header: str) -> str | None:\n",
    "    parts = header.split(\".\")\n",
    "    if len(parts) > 1:\n",
    "        return parts[1].split()[0]\n",
    "    return None\n",
    "\n",
    "for file_path in input_dir.glob(\"*.fa\"):\n",
    "    with open(file_path) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    filtered_lines = []\n",
    "    keep = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\">\"):\n",
    "            gene = extract_gene(line)\n",
    "            header_transcript = line.split()[0].lstrip(\">\").split(\".\")[0]\n",
    "            keep = gene in gene_symbols and header_transcript in toga_transcripts\n",
    "        if keep:\n",
    "            filtered_lines.append(line)\n",
    "\n",
    "    if filtered_lines:\n",
    "        out_file = filtered_dir / file_path.name\n",
    "        with open(out_file, \"w\") as fo:\n",
    "            fo.writelines(filtered_lines)\n",
    "\n",
    "print(\"Fasta filtering completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc02ee",
   "metadata": {},
   "source": [
    "## 2) Load human bHLH domain coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015aadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_domain = pd.read_csv(domain_csv, dtype=str)\n",
    "df_domain.columns = [c.strip() for c in df_domain.columns]\n",
    "\n",
    "domain_info = {}\n",
    "for _, r in df_domain.iterrows():\n",
    "    enst = r[\"ensembl_transcript_id\"].strip()\n",
    "    try:\n",
    "        start = int(float(r[\"interpro_start\"]))\n",
    "        end = int(float(r[\"interpro_end\"]))\n",
    "    except Exception:\n",
    "        continue\n",
    "    domain_info[enst] = {\n",
    "        \"HGNC\": r[\"HGNC symbol\"].strip(),\n",
    "        \"human_start\": start,\n",
    "        \"human_end\": end,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d75b9",
   "metadata": {},
   "source": [
    "## 3) Map human domain positions to aligned orthologs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e26e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_domain(ref_seq: str, query_seq: str, domain_start: int, domain_end: int):\n",
    "    if len(ref_seq) != len(query_seq):\n",
    "        raise ValueError(\"Alignment length mismatch\")\n",
    "    human_pos = 0\n",
    "    query_pos = 0\n",
    "    q_start = None\n",
    "    q_end = None\n",
    "    for r, q in zip(ref_seq, query_seq):\n",
    "        if r != \"-\":\n",
    "            human_pos += 1\n",
    "        if q != \"-\":\n",
    "            query_pos += 1\n",
    "        if human_pos == domain_start and q_start is None:\n",
    "            q_start = query_pos\n",
    "        if human_pos == domain_end and q_end is None:\n",
    "            q_end = query_pos\n",
    "            break\n",
    "    return q_start, q_end\n",
    "\n",
    "results = []\n",
    "header_re = re.compile(r\"^>?(.+) \\| PROT \\| (REFERENCE|QUERY)\")\n",
    "\n",
    "for filepath in filtered_dir.glob(\"*.fa\"):\n",
    "    raw_species = filepath.stem\n",
    "    species = species_map.get(raw_species, raw_species)\n",
    "\n",
    "    seqs_by_transcript = defaultdict(dict)\n",
    "    for rec in SeqIO.parse(filepath, \"fasta\"):\n",
    "        desc = rec.description\n",
    "        m = header_re.search(desc)\n",
    "        if not m:\n",
    "            continue\n",
    "        enst = m.group(1).split()[0]\n",
    "        label = m.group(2).upper()\n",
    "        seqs_by_transcript[enst][label] = str(rec.seq)\n",
    "\n",
    "    for enst, seqs in seqs_by_transcript.items():\n",
    "        enst_key = enst.split(\".\")[0]\n",
    "        if enst_key not in domain_info:\n",
    "            continue\n",
    "        if \"REFERENCE\" not in seqs or \"QUERY\" not in seqs:\n",
    "            continue\n",
    "        ref_seq = seqs[\"REFERENCE\"]\n",
    "        query_seq = seqs[\"QUERY\"]\n",
    "        info = domain_info[enst_key]\n",
    "        try:\n",
    "            q_start, q_end = map_domain(ref_seq, query_seq, info[\"human_start\"], info[\"human_end\"])\n",
    "        except Exception:\n",
    "            q_start, q_end = None, None\n",
    "\n",
    "        results.append({\n",
    "            \"HGNC\": info[\"HGNC\"],\n",
    "            \"ENST\": enst_key,\n",
    "            \"full_enst_label\": enst,\n",
    "            \"target_species\": species,\n",
    "            \"human_start\": info[\"human_start\"],\n",
    "            \"human_end\": info[\"human_end\"],\n",
    "            \"query_start\": q_start,\n",
    "            \"query_end\": q_end,\n",
    "        })\n",
    "\n",
    "df_zoo = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec56f91",
   "metadata": {},
   "source": [
    "## 4) Merge with TOGA and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e94c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toga_subset = df_toga[[\"t_transcript_clean\", \"homology_type\", \"HGNC symbol\", \"target_species\"]].drop_duplicates()\n",
    "\n",
    "df_final = df_zoo.merge(\n",
    "    df_toga_subset,\n",
    "    left_on=[\"ENST\", \"target_species\"],\n",
    "    right_on=[\"t_transcript_clean\", \"target_species\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_final = df_final.rename(columns={\"HGNC symbol\": \"HGNC_final\"})\n",
    "\n",
    "final_cols = [\n",
    "    \"HGNC\", \"ENST\", \"full_enst_label\", \"target_species\",\n",
    "    \"human_start\", \"human_end\", \"query_start\", \"query_end\", \"homology_type\"\n",
    "]\n",
    "\n",
    "df_final = df_final[final_cols]\n",
    "\n",
    "df_final.to_csv(output_file, index=False)\n",
    "print(f\"Saved: {output_file}\")\n",
    "print(f\"Rows: {len(df_final)}, species: {df_final['target_species'].nunique()}, genes: {df_final['HGNC'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7aa15d",
   "metadata": {},
   "source": [
    "## 5) Quality controls (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final = pd.read_csv(output_file)\n",
    "\n",
    "null_coords = df_final[df_final['query_start'].isna() | df_final['query_end'].isna()]\n",
    "null_counts = null_coords.groupby('target_species').size().reset_index(name='null_count')\n",
    "\n",
    "print(\"Entries with null query_start or query_end per species:\")\n",
    "print(null_counts.to_string(index=False))\n",
    "\n",
    "valid_coords = df_final[df_final['query_start'].notna() & df_final['query_end'].notna()]\n",
    "\n",
    "gene_species_valid = valid_coords.groupby(['HGNC', 'target_species']).size().reset_index(name='count')\n",
    "\n",
    "missing_genes = []\n",
    "for gene in df_final['HGNC'].unique():\n",
    "    for sp in df_final['target_species'].unique():\n",
    "        if not ((gene_species_valid['HGNC'] == gene) & (gene_species_valid['target_species'] == sp)).any():\n",
    "            missing_genes.append({'HGNC': gene, 'target_species': sp})\n",
    "\n",
    "if missing_genes:\n",
    "    print(f\"Missing valid entries (sample): {len(missing_genes)}\")\n",
    "    print(pd.DataFrame(missing_genes).head(20))\n",
    "else:\n",
    "    print(\"All genes have at least one valid entry per species.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f335b",
   "metadata": {},
   "source": [
    "## 6) Compare with Ensembl (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798dd669",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo_file = p(\"data\", \"intermediate\", \"zoonomia\", \"Zoonomia_Start_End_final.csv\")\n",
    "annot_file = p(\"data\", \"intermediate\", \"orthologs\", \"annotated_bHLH_merged_data_with_gene_names.csv\")\n",
    "output_report = p(\"outputs\", \"reports\", \"report_comparison.csv\")\n",
    "Path(output_report).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_zoo = pd.read_csv(zoo_file)\n",
    "df_annot = pd.read_csv(annot_file)\n",
    "\n",
    "df_zoo_filtered = df_zoo[(df_zoo[\"query_start\"] > 0) & (df_zoo[\"query_end\"] > 0)].copy()\n",
    "\n",
    "df_compare = df_zoo_filtered.merge(\n",
    "    df_annot,\n",
    "    left_on=['HGNC', 'target_species'],\n",
    "    right_on=['HGNC symbol', 'target_species_name'],\n",
    "    how='outer',\n",
    "    suffixes=('_zoo', '_annot')\n",
    ")\n",
    "\n",
    "df_compare = df_compare.drop(columns=['HGNC symbol', 'target_species_name'], errors='ignore')\n",
    "\n",
    "df_compare[\"target_species\"] = df_compare[\"target_species_zoo\"].fillna(df_compare[\"target_species_annot\"])\n",
    "\n",
    "df_compare = df_compare.drop(columns=['target_species_zoo', 'target_species_annot'], errors='ignore')\n",
    "\n",
    "df_compare['diff_start'] = df_compare['query_start'].fillna(0) - df_compare['Start_Q'].fillna(0)\n",
    "df_compare['diff_end'] = df_compare['query_end'].fillna(0) - df_compare['Stop_Q'].fillna(0)\n",
    "\n",
    "homology_map = {\n",
    "    'ortholog_one2one': 'one2one',\n",
    "    'ortholog_one2many': 'one2many',\n",
    "    'ortholog_many2many': 'many2many'\n",
    "}\n",
    "\n",
    "df_compare['homology_type_annot_mapped'] = df_compare['homology_type_annot'].map(homology_map)\n",
    "\n",
    "df_compare['homology_match'] = (\n",
    "    df_compare['homology_type_zoo'] == df_compare['homology_type_annot_mapped']\n",
    ")\n",
    "\n",
    "df_compare['present_in_zoo'] = df_compare['query_start'].notna()\n",
    "df_compare['present_in_annot'] = df_compare['Start_Q'].notna()\n",
    "\n",
    "report_cols = [\n",
    "    'HGNC', 'ENST', 'target_species',\n",
    "    'query_start', 'query_end',\n",
    "    'Start_Q', 'Stop_Q',\n",
    "    'diff_start', 'diff_end',\n",
    "    'homology_type_zoo', 'homology_type_annot_mapped', 'homology_match',\n",
    "    'present_in_zoo', 'present_in_annot'\n",
    "]\n",
    "\n",
    "df_report = df_compare[report_cols].sort_values(['HGNC', 'target_species'])\n",
    "\n",
    "df_report.to_csv(output_report, index=False)\n",
    "print(f\"Saved report: {output_report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5109564",
   "metadata": {},
   "source": [
    "## Exploratory notes (optional)\n",
    "\n",
    "- Zoonomia alignments include both REFERENCE and QUERY sequences; only pairs with both are used.\n",
    "- The TOGA transcript IDs are normalized by removing version suffixes (e.g., `ENST...1.2` â†’ `ENST...1`).\n",
    "- If column naming is inconsistent across sources, prefer standardizing to `HGNC`, `ENST`, and `target_species` before merging.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
